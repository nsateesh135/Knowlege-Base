{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrapping \n",
    " - techniques involving automating the gathering of data from a website\n",
    "\n",
    "## Rules of web scraping \n",
    "- Always try to get permission before scrapping\n",
    "- If you make too many scraping attempts or requests your IP address could be blocked \n",
    "- Some sites automatically block scraping software \n",
    "\n",
    "## Limitations of web scraping\n",
    "- Every website is unique so every web scraping is unique \n",
    "- A slight change or update to the website may completely break web scraping script\n",
    "\n",
    "## Main front end components \n",
    "- HTML : Hypertext markdown language - Used to create basic structure and content of \n",
    "         a webpage \n",
    "- CSS : Cascading Style Sheets  - used for design and  style(color, font) of a webpage\n",
    "- JS : Java Script - used to add interactivity to webpage\n",
    "\n",
    "# Deeper dive into HTML code \n",
    "```\n",
    "<!DOCTYPE Html>\n",
    "<html>\n",
    "   <head>\n",
    "     <title> Title on Browser Tab </title>\n",
    "   </head>\n",
    "   <body>\n",
    "       <h1> Website Header </h1>\n",
    "       <p> Some Paragraph </p>\n",
    "   </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "# Deeper dive into CSS \n",
    "- CSS uses tags to define what html elements will be styled \n",
    "- styles.css is a file\n",
    "- '#' refers to id and '.' refers to a class\n",
    "```\n",
    "<!DOCTYPE Html>\n",
    "<html>\n",
    "   <head>\n",
    "     <link rel=\"stylesheets\" href = \"styles.css\" >\n",
    "     <title> Title on Browser Tab </title>\n",
    "   </head>\n",
    "   <body>\n",
    "       <h1> Website Header </h1>\n",
    "       <p id ='para2'> Some Paragraph </p>\n",
    "   </body>\n",
    "```\n",
    "- what is within styles.css?\n",
    "```\n",
    "p{\n",
    "   color:red;\n",
    "   font-family:courier;\n",
    "   font-size:160%;\n",
    "}\n",
    ".someclass{\n",
    "    color:green;\n",
    "   font-family:verdana;\n",
    "   font-size:300%;\n",
    "}\n",
    "#someid{\n",
    "    color:blue;\n",
    "#para2{\n",
    "    color:red;\n",
    "}\n",
    ".cool{\n",
    "   color:green;\n",
    "   font-family:verdana;\n",
    "   font-size:300%;\n",
    "}\n",
    "}\n",
    "```\n",
    "\n",
    "# Libraries to install \n",
    "conda install requests \n",
    "conda install lxml - This package is needed by beautiful soup\n",
    "conda install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the title of a page\n",
    "# result :returns a response object [requests.models.Response]\n",
    "# result.text : returns the entire html document as text but not in a readable format\n",
    "# soup : returns beautiful soup created text which is easily parsable\n",
    "# soup.select() : helps us search for the tag. The output is a list\n",
    "# .getTest : method used to extract text from tag\n",
    "import requests\n",
    "import bs4\n",
    "result = requests.get(\"https://www.kristaseiden.com\")\n",
    "soup = bs4.BeautifulSoup(result.text,\"lxml\")\n",
    "soup.select('title')[0].getText()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use soup.select()?\n",
    "soup.select('div') - all elements with 'div' tag \n",
    "soup.select(#some_id) - elements containing id = 'some_id'\n",
    "soup.select(.some_class) - elements containing class = 'some_class'\n",
    "soup.select('div span') - any elements namesd span within a div element\n",
    "soup.select('div>span') - any elements named span directly within a div element, with\n",
    "                          nothing in between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing all elements of a class \n",
    "import requests\n",
    "import bs4\n",
    "result = requests.get(\"https://www.kristaseiden.com\")\n",
    "soup = bs4.BeautifulSoup(result.text,\"lxml\")\n",
    "\n",
    "for widgets in soup.select('.widget-head'):\n",
    "    print(widgets.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing an image and save on local \n",
    "# Beautiful Soup can scan a page,locate the <img> tag and grab these urls's\n",
    "# We can then download the URL's as images and write them to a computer\n",
    "# Always check copyright permissions before downloading and using an image from a website\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "\n",
    "result = requests.get(\"https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)\")\n",
    "soup = bs4.BeautifulSoup(result.text,\"lxml\")\n",
    "first_image = soup.select('.thumbimage')[0]\n",
    "\n",
    "image_src = \"https:\" +first_image['src']\n",
    "image_link = requests.get(image_src)\n",
    "with open (\"deep blue processor.jpg\",\"wb\") as f:\n",
    "    f.write(image_link.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project : https://toscrape.com/\n",
    "# TODO : Get title of every book with a 2 star rating\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "\n",
    "book_title_2_star_rating = []\n",
    "for i in range(1,51):\n",
    "    result = requests.get(f\"http://books.toscrape.com/catalogue/page-{i}.html\")\n",
    "    soup = bs4.BeautifulSoup(result.text,\"lxml\")\n",
    "    for product in soup.select('.product_pod'):\n",
    "        if product.select('.star-rating.Two') != []:\n",
    "            book_title_2_star_rating.append(product.select('a')[1]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import bs4\n",
    "\n",
    "result = requests.get(\"http://quotes.toscrape.com/\")\n",
    "soup = bs4.BeautifulSoup(result.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Albert Einstein',\n",
       " 'André Gide',\n",
       " 'Eleanor Roosevelt',\n",
       " 'J.K. Rowling',\n",
       " 'Jane Austen',\n",
       " 'Marilyn Monroe',\n",
       " 'Steve Martin',\n",
       " 'Thomas A. Edison'}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get unique authors \n",
    "author = set()\n",
    "for authors in soup.select(\".author\"):\n",
    "    author.add(authors.text)\n",
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”',\n",
       " 'by Albert Einstein\\n(about)\\n',\n",
       " '“It is our choices, Harry, that show what we truly are, far more than our abilities.”',\n",
       " 'by J.K. Rowling\\n(about)\\n',\n",
       " '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”',\n",
       " 'by Albert Einstein\\n(about)\\n',\n",
       " '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”',\n",
       " 'by Jane Austen\\n(about)\\n',\n",
       " \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\",\n",
       " 'by Marilyn Monroe\\n(about)\\n',\n",
       " '“Try not to become a man of success. Rather become a man of value.”',\n",
       " 'by Albert Einstein\\n(about)\\n',\n",
       " '“It is better to be hated for what you are than to be loved for what you are not.”',\n",
       " 'by André Gide\\n(about)\\n',\n",
       " \"“I have not failed. I've just found 10,000 ways that won't work.”\",\n",
       " 'by Thomas A. Edison\\n(about)\\n',\n",
       " \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\",\n",
       " 'by Eleanor Roosevelt\\n(about)\\n',\n",
       " '“A day without sunshine is like, you know, night.”',\n",
       " 'by Steve Martin\\n(about)\\n',\n",
       " '\\nlove\\n',\n",
       " '\\ninspirational\\n',\n",
       " '\\nlife\\n',\n",
       " '\\nhumor\\n',\n",
       " '\\nbooks\\n',\n",
       " '\\nreading\\n',\n",
       " '\\nfriendship\\n',\n",
       " '\\nfriends\\n',\n",
       " '\\ntruth\\n',\n",
       " '\\nsimile\\n']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth_quotes = []\n",
    "for quotes in soup.select(\"div>span\"):\n",
    "    quote = quotes.getText()\n",
    "    auth_quotes.append(quote)\n",
    "auth_quotes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "love\n",
      "\n",
      "\n",
      "inspirational\n",
      "\n",
      "\n",
      "life\n",
      "\n",
      "\n",
      "humor\n",
      "\n",
      "\n",
      "books\n",
      "\n",
      "\n",
      "reading\n",
      "\n",
      "\n",
      "friendship\n",
      "\n",
      "\n",
      "friends\n",
      "\n",
      "\n",
      "truth\n",
      "\n",
      "\n",
      "simile\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in soup.select(\".tag-item\"):\n",
    "    print(item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Albert Einstein',\n",
       " 'Alexandre Dumas fils',\n",
       " 'Alfred Tennyson',\n",
       " 'Allen Saunders',\n",
       " 'André Gide',\n",
       " 'Ayn Rand',\n",
       " 'Bob Marley',\n",
       " 'C.S. Lewis',\n",
       " 'Charles Bukowski',\n",
       " 'Charles M. Schulz',\n",
       " 'Douglas Adams',\n",
       " 'Dr. Seuss',\n",
       " 'E.E. Cummings',\n",
       " 'Eleanor Roosevelt',\n",
       " 'Elie Wiesel',\n",
       " 'Ernest Hemingway',\n",
       " 'Friedrich Nietzsche',\n",
       " 'Garrison Keillor',\n",
       " 'George Bernard Shaw',\n",
       " 'George Carlin',\n",
       " 'George Eliot',\n",
       " 'George R.R. Martin',\n",
       " 'Harper Lee',\n",
       " 'Haruki Murakami',\n",
       " 'Helen Keller',\n",
       " 'J.D. Salinger',\n",
       " 'J.K. Rowling',\n",
       " 'J.M. Barrie',\n",
       " 'J.R.R. Tolkien',\n",
       " 'James Baldwin',\n",
       " 'Jane Austen',\n",
       " 'Jim Henson',\n",
       " 'Jimi Hendrix',\n",
       " 'John Lennon',\n",
       " 'Jorge Luis Borges',\n",
       " 'Khaled Hosseini',\n",
       " \"Madeleine L'Engle\",\n",
       " 'Marilyn Monroe',\n",
       " 'Mark Twain',\n",
       " 'Martin Luther King Jr.',\n",
       " 'Mother Teresa',\n",
       " 'Pablo Neruda',\n",
       " 'Ralph Waldo Emerson',\n",
       " 'Stephenie Meyer',\n",
       " 'Steve Martin',\n",
       " 'Suzanne Collins',\n",
       " 'Terry Pratchett',\n",
       " 'Thomas A. Edison',\n",
       " 'W.C. Fields',\n",
       " 'William Nicholson'}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution 1: \n",
    "author = set()\n",
    "for i in range(1,15):\n",
    "        result = requests.get(f\"http://quotes.toscrape.com/page/{i}/\")\n",
    "        if 'No quotes found!' not in result.text:\n",
    "                soup = bs4.BeautifulSoup(result.text,\"lxml\")\n",
    "                for authors in soup.select(\".author\"):\n",
    "                        author.add(authors.text)\n",
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 2\n",
    "\n",
    "page_still_valid = True\n",
    "authors = set()\n",
    "page = 1\n",
    "\n",
    "while page_still_valid:\n",
    "\n",
    "    # Concatenate to get new page URL\n",
    "    page_url = url+str(page)\n",
    "    \n",
    "    # Obtain Request\n",
    "    res = requests.get(page_url)\n",
    "    \n",
    "    # Check to see if we're on the last page\n",
    "    if \"No quotes found!\" in res.text:\n",
    "        break\n",
    "    \n",
    "    # Turn into Soup\n",
    "    soup = bs4.BeautifulSoup(res.text,'lxml')\n",
    "    \n",
    "    # Add Authors to our set\n",
    "    for name in soup.select(\".author\"):\n",
    "        authors.add(name.text)\n",
    "        \n",
    "    # Go to Next Page\n",
    "    page += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project : Scrape product Stats from live website (https://www.mydeal.com.au/sale/sensor-bins)\n",
    "\n",
    "import random \n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define Global Variables\n",
    "\n",
    "required_url = 'https://www.mydeal.com.au/sale/sensor-bins'\n",
    "\n",
    "user_agent_list = [\n",
    "    # This list could be automated with new user agent periodically \n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 13_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15'\n",
    "]\n",
    "\n",
    "def get_html_text(required_url,user_agent_list):\n",
    "    \"\"\"\n",
    "    This function is used to retrieve html document text for the a particular url\n",
    "\n",
    "    Args: \n",
    "    required_url (str) : A particular url from which we want to scrape data \n",
    "    user_agent_list (lst): A list of user agent \n",
    "\n",
    "    Output:\n",
    "    response (str) : html text\n",
    "    \"\"\"\n",
    "    result = ''\n",
    "    headers = {}\n",
    "    num_user_agent = len(user_agent_list)\n",
    "    user_agent_pointer = 0\n",
    "    try:\n",
    "        while result.lower()!= 'ok' and user_agent_pointer<num_user_agent :\n",
    "            for i in user_agent_list:\n",
    "                headers['User-Agent'] = i\n",
    "                request = requests.get(required_url,headers = headers)\n",
    "                result = request.reason\n",
    "                user_agent_pointer+= 1\n",
    "                if result.lower() == 'ok':\n",
    "                    # request.text : returns the entire html document as text but not in a readable format\n",
    "                    return request.text\n",
    "                    break\n",
    "                else:\n",
    "                    print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Check code :{e} - error was detected\")\n",
    "\n",
    "\n",
    "def get_product_title(soup):\n",
    "    \"\"\"\n",
    "    This function is used to extract product title \n",
    "    Args:\n",
    "    soup : Beautiful soup created text which is easily parsable\n",
    "\n",
    "    Output:\n",
    "    product_title (lst) - List of product title from the page\n",
    "    \"\"\"\n",
    "    try :\n",
    "        product_title = []\n",
    "        for i in soup.select('.deal-title'):\n",
    "            product_title.append(i.getText().replace('\\n','').replace('\\r','').lstrip().rstrip())\n",
    "        return product_title\n",
    "    except Exception as e :\n",
    "        print(f\"Check code :{e} - error was detected\")\n",
    "\n",
    "def get_product_price(soup):\n",
    "    \"\"\"\n",
    "    This function is used to extract product price\n",
    "    Args:\n",
    "    soup : Beautiful soup created text which is easily parsable\n",
    "\n",
    "    Output:\n",
    "    deal_price (lst) - List of product price from the page\n",
    "    \"\"\"\n",
    "    try :\n",
    "        product_price = []\n",
    "        product_tag = []\n",
    "\n",
    "        for i in soup.select('.deal-title'):\n",
    "          product_tag.append('#'+i.find_all('a')[0].get('id').replace('dealtitle','dealprice'))\n",
    "\n",
    "        for tag in product_tag:\n",
    "          product_price.append(soup.select(tag)[0].getText())\n",
    "        return product_price \n",
    "    except Exception as e :\n",
    "        print(f\"Check code :{e} - error was detected\")\n",
    "        \n",
    "def get_product_rating(soup):\n",
    "    \"\"\"\n",
    "    This function is used to extract product rating\n",
    "    Args:\n",
    "    soup : Beautiful soup created text which is easily parsable\n",
    "\n",
    "    Output:\n",
    "    deal_rating (lst) - List of product ratings from the page\n",
    "    \"\"\"\n",
    "    try :\n",
    "        product_rating = []\n",
    "\n",
    "        for rating in soup.select('.product-review-link'):\n",
    "            product_rating.append(int(rating.getText().strip('()')))\n",
    "        return product_rating\n",
    "    except Exception as e :\n",
    "        print(f\"Check code :{e} - error was detected\")\n",
    "\n",
    "def main ():\n",
    "\n",
    "    soup = BeautifulSoup(get_html_text(required_url,user_agent_list),\"lxml\")\n",
    "    data = {}\n",
    "    data['last_updated_date'] = pd.to_datetime('today').strftime(\"%Y-%m-%d\")\n",
    "    data['product_title'] = get_product_title(soup)\n",
    "    data['product_price'] = get_product_price(soup)\n",
    "    prod_data = pd.DataFrame(data)\n",
    "    return prod_data\n",
    "\n",
    "\n",
    "\"\"\"When a Python script is executed, \n",
    "Python sets the __name__ attribute of the module to \"__main__\" if the script is the entry point of execution. \n",
    "If the script is imported as a module into another script, __name__ is set to the name of the script/module.\n",
    "\"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
